{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior cloning to train DNN agents for shiftable loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, CSV\n",
    "using BSON: @save, @load\n",
    "using BSON, NPZ\n",
    "using TOML\n",
    "using Flux, MLJ\n",
    "using StatsBase\n",
    "using Random\n",
    "using Plots, Plots.Measures\n",
    "using Revise, HEMS\n",
    "\n",
    "ENV[\"COLUMNS\"] = 2000\n",
    "Random.seed!(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots default\n",
    "default(; labelfontsize = 13, tickfontsize = 11,\n",
    "    framestyle = :box,\n",
    "    margin = 0.5mm,\n",
    "    legendfontsize=11,\n",
    "    xticks=:auto\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read expert dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../../\"\n",
    "\n",
    "home_dir = joinpath(root_dir, \"data/home/\")\n",
    "IL_data_dir = joinpath(root_dir, \"data/learning/IL\")\n",
    "IL_model_dir = joinpath(root_dir, \"model/IL\")\n",
    "img_dir = joinpath(root_dir, \"img\")\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = read_home_config(joinpath(home_dir, \"home.toml\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeySet for a Dict{String, Tuple{Matrix{Float64}, Vector{Float64}}} with 6 entries. Keys:\n",
       "  \"EV\"\n",
       "  \"AC1\"\n",
       "  \"AC2\"\n",
       "  \"DW\"\n",
       "  \"H\"\n",
       "  \"WM\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `d` and `dt` are training set and test set respectively\n",
    "@load joinpath(IL_data_dir, \"train_xy.bson\") d\n",
    "\n",
    "dt = BSON.load(joinpath(IL_data_dir, \"test_xy.bson\"))[:d];\n",
    "keys(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train agents for shiftable loads\n",
    "- Train a DNN-based agent \n",
    "- Report performance \n",
    "- Store the obtained agent\n",
    "\n",
    "We empirically found that the same set of hyperparameters worked well for all shiftable loads in this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "report_classification_perf (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function report_classification_perf(agent, X, y)\n",
    "\n",
    "    ŷ = vec(agent(X) .>= 0.5) \n",
    "    acc = MLJ.accuracy(ŷ, y)\n",
    "    # cm = MLJ.confusion_matrix(coerce(ŷ, OrderedFactor), coerce(y, OrderedFactor))\n",
    "    cm = MLJ.confusion_matrix(categorical(ŷ; ordered = true), categorical(y; ordered = true))\n",
    "    f1 = MLJ.f1score(ŷ, y)\n",
    "    @show cm acc f1\n",
    "    nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{String}:\n",
       " \"WM\"\n",
       " \"DW\"\n",
       " \"EV\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents = Agent[]\n",
    "shiftable_loads = [l[\"id\"] for l in Iterators.Flatten((h[\"SU\"], h[\"SI\"]))]\n",
    "loss_histories = []\n",
    "shiftable_loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id = \"WM\"\n",
      "size(X) = (3, 3655)\n",
      "size(Xt) = (3, 1825)\n",
      "id = \"DW\"\n",
      "size(X) = (3, 2193)\n",
      "size(Xt) = (3, 1095)\n",
      "id = \"EV\"\n",
      "size(X) = (4, 5848)\n",
      "size(Xt) = (4, 2920)\n",
      " 79.070252 seconds (89.48 M allocations: 25.077 GiB, 4.35% gc time, 54.02% compilation time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0013333333333333333\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0008888888888888888\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0005925925925925926\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0003950617283950617\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0002633744855967078\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0001755829903978052\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.00011705532693187012\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 7.803688462124675e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 5.2024589747497834e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 3.468305983166522e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 2.3122039887776814e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 1.5414693258517875e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 1.027646217234525e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 6.8509747815635e-6\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 20 epochs. Early stopped.\n",
      "│   best_loss_val = 0.49204061546647715\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:153\n",
      "┌ Info: The minimum validation loss is 0.49204061546647715\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:160\n",
      "┌ Warning: Number of observations less than batchsize, decreasing the batchsize to 219\n",
      "└ @ Flux.Data C:\\Users\\shuhu\\.julia\\packages\\Flux\\BPPNj\\src\\data\\dataloader.jl:82\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0013333333333333333\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0008888888888888888\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0005925925925925926\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0003950617283950617\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0002633744855967078\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0001755829903978052\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.00011705532693187012\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 7.803688462124675e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 5.2024589747497834e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 3.468305983166522e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 2.3122039887776814e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 1.5414693258517875e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 1.027646217234525e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 6.8509747815635e-6\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 20 epochs. Early stopped.\n",
      "│   best_loss_val = 0.3672494743977907\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:153\n",
      "┌ Info: The minimum validation loss is 0.3672494743977907\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:160\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0013333333333333333\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0008888888888888888\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0005925925925925926\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0003950617283950617\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0002633744855967078\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.0001755829903978052\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 0.00011705532693187012\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 7.803688462124675e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 5.2024589747497834e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 3.468305983166522e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 2.3122039887776814e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 1.5414693258517875e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 1.027646217234525e-5\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 10 epochs. Drop learning rate to\n",
      "│   η = 6.8509747815635e-6\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:149\n",
      "┌ Info: No improvement in 20 epochs. Early stopped.\n",
      "│   best_loss_val = 0.5767025980622168\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:153\n",
      "┌ Info: The minimum validation loss is 0.5767025980622168\n",
      "└ @ HEMS f:\\github\\HEMS-IL\\src\\HEMS\\src\\IL\\BC.jl:160\n"
     ]
    }
   ],
   "source": [
    "@time begin\n",
    "for id in shiftable_loads\n",
    "    X, y = d[id]\n",
    "    Xt, yt = dt[id]\n",
    "    @show id size(X) size(Xt)\n",
    "    \n",
    "    agent, loss_hist = train_SU_agent(X, y; device = Flux.cpu, epochs = 500, η = 0.2e-2,\n",
    "        report_freq = 0, w1 = 2.5)\n",
    "    push!(agents, agent)\n",
    "    push!(loss_histories, loss_hist)\n",
    "end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id = \"EV\"\n",
      "ne = 196\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"610\" height=\"220\" viewBox=\"0 0 2440 880\">\n<defs>\n  <clipPath id=\"clip210\">\n    <rect x=\"0\" y=\"0\" width=\"2440\" height=\"880\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip210)\" d=\"\nM0 880 L2440 880 L2440 0 L0 0  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip211\">\n    <rect x=\"488\" y=\"0\" width=\"1709\" height=\"880\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip210)\" d=\"\nM236.659 697.001 L2384.88 697.001 L2384.88 15.748 L236.659 15.748  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip212\">\n    <rect x=\"236\" y=\"15\" width=\"2149\" height=\"682\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  297.457,697.001 297.457,15.748 \n  \"/>\n<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  817.105,697.001 817.105,15.748 \n  \"/>\n<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1336.75,697.001 1336.75,15.748 \n  \"/>\n<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  1856.4,697.001 1856.4,15.748 \n  \"/>\n<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  2376.05,697.001 2376.05,15.748 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  236.659,697.001 2384.88,697.001 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  236.659,15.748 2384.88,15.748 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  297.457,697.001 297.457,678.103 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  817.105,697.001 817.105,678.103 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1336.75,697.001 1336.75,678.103 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1856.4,697.001 1856.4,678.103 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2376.05,697.001 2376.05,678.103 \n  \"/>\n<path clip-path=\"url(#clip210)\" d=\"M297.457 732.634 Q292.492 732.634 289.978 737.535 Q287.495 742.405 287.495 752.208 Q287.495 761.98 289.978 766.881 Q292.492 771.751 297.457 771.751 Q302.454 771.751 304.937 766.881 Q307.452 761.98 307.452 752.208 Q307.452 742.405 304.937 737.535 Q302.454 732.634 297.457 732.634 M297.457 727.541 Q305.446 727.541 309.648 733.875 Q313.881 740.177 313.881 752.208 Q313.881 764.208 309.648 770.542 Q305.446 776.844 297.457 776.844 Q289.468 776.844 285.235 770.542 Q281.034 764.208 281.034 752.208 Q281.034 740.177 285.235 733.875 Q289.468 727.541 297.457 727.541 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M782.316 728.401 L807.556 728.401 L807.556 733.811 L788.205 733.811 L788.205 745.461 Q789.605 744.983 791.006 744.76 Q792.406 744.506 793.807 744.506 Q801.764 744.506 806.411 748.866 Q811.058 753.227 811.058 760.675 Q811.058 768.345 806.283 772.61 Q801.509 776.844 792.82 776.844 Q789.828 776.844 786.709 776.334 Q783.621 775.825 780.311 774.807 L780.311 768.345 Q783.176 769.905 786.231 770.669 Q789.287 771.433 792.693 771.433 Q798.199 771.433 801.414 768.536 Q804.628 765.64 804.628 760.675 Q804.628 755.709 801.414 752.813 Q798.199 749.917 792.693 749.917 Q790.114 749.917 787.536 750.49 Q784.99 751.062 782.316 752.272 L782.316 728.401 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M837.475 732.634 Q832.51 732.634 829.996 737.535 Q827.513 742.405 827.513 752.208 Q827.513 761.98 829.996 766.881 Q832.51 771.751 837.475 771.751 Q842.472 771.751 844.955 766.881 Q847.469 761.98 847.469 752.208 Q847.469 742.405 844.955 737.535 Q842.472 732.634 837.475 732.634 M837.475 727.541 Q845.464 727.541 849.666 733.875 Q853.899 740.177 853.899 752.208 Q853.899 764.208 849.666 770.542 Q845.464 776.844 837.475 776.844 Q829.486 776.844 825.253 770.542 Q821.052 764.208 821.052 752.208 Q821.052 740.177 825.253 733.875 Q829.486 727.541 837.475 727.541 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1281.21 770.51 L1291.72 770.51 L1291.72 734.257 L1280.29 736.549 L1280.29 730.692 L1291.65 728.401 L1298.08 728.401 L1298.08 770.51 L1308.58 770.51 L1308.58 775.921 L1281.21 775.921 L1281.21 770.51 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1335.32 732.634 Q1330.36 732.634 1327.84 737.535 Q1325.36 742.405 1325.36 752.208 Q1325.36 761.98 1327.84 766.881 Q1330.36 771.751 1335.32 771.751 Q1340.32 771.751 1342.8 766.881 Q1345.31 761.98 1345.31 752.208 Q1345.31 742.405 1342.8 737.535 Q1340.32 732.634 1335.32 732.634 M1335.32 727.541 Q1343.31 727.541 1347.51 733.875 Q1351.74 740.177 1351.74 752.208 Q1351.74 764.208 1347.51 770.542 Q1343.31 776.844 1335.32 776.844 Q1327.33 776.844 1323.1 770.542 Q1318.9 764.208 1318.9 752.208 Q1318.9 740.177 1323.1 733.875 Q1327.33 727.541 1335.32 727.541 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1376.79 732.634 Q1371.83 732.634 1369.31 737.535 Q1366.83 742.405 1366.83 752.208 Q1366.83 761.98 1369.31 766.881 Q1371.83 771.751 1376.79 771.751 Q1381.79 771.751 1384.27 766.881 Q1386.79 761.98 1386.79 752.208 Q1386.79 742.405 1384.27 737.535 Q1381.79 732.634 1376.79 732.634 M1376.79 727.541 Q1384.78 727.541 1388.98 733.875 Q1393.22 740.177 1393.22 752.208 Q1393.22 764.208 1388.98 770.542 Q1384.78 776.844 1376.79 776.844 Q1368.8 776.844 1364.57 770.542 Q1360.37 764.208 1360.37 752.208 Q1360.37 740.177 1364.57 733.875 Q1368.8 727.541 1376.79 727.541 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1800.86 770.51 L1811.36 770.51 L1811.36 734.257 L1799.94 736.549 L1799.94 730.692 L1811.3 728.401 L1817.73 728.401 L1817.73 770.51 L1828.23 770.51 L1828.23 775.921 L1800.86 775.921 L1800.86 770.51 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1841.28 728.401 L1866.52 728.401 L1866.52 733.811 L1847.17 733.811 L1847.17 745.461 Q1848.57 744.983 1849.97 744.76 Q1851.37 744.506 1852.77 744.506 Q1860.73 744.506 1865.38 748.866 Q1870.02 753.227 1870.02 760.675 Q1870.02 768.345 1865.25 772.61 Q1860.47 776.844 1851.79 776.844 Q1848.79 776.844 1845.67 776.334 Q1842.59 775.825 1839.28 774.807 L1839.28 768.345 Q1842.14 769.905 1845.2 770.669 Q1848.25 771.433 1851.66 771.433 Q1857.16 771.433 1860.38 768.536 Q1863.59 765.64 1863.59 760.675 Q1863.59 755.709 1860.38 752.813 Q1857.16 749.917 1851.66 749.917 Q1849.08 749.917 1846.5 750.49 Q1843.96 751.062 1841.28 752.272 L1841.28 728.401 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1896.44 732.634 Q1891.48 732.634 1888.96 737.535 Q1886.48 742.405 1886.48 752.208 Q1886.48 761.98 1888.96 766.881 Q1891.48 771.751 1896.44 771.751 Q1901.44 771.751 1903.92 766.881 Q1906.43 761.98 1906.43 752.208 Q1906.43 742.405 1903.92 737.535 Q1901.44 732.634 1896.44 732.634 M1896.44 727.541 Q1904.43 727.541 1908.63 733.875 Q1912.86 740.177 1912.86 752.208 Q1912.86 764.208 1908.63 770.542 Q1904.43 776.844 1896.44 776.844 Q1888.45 776.844 1884.22 770.542 Q1880.02 764.208 1880.02 752.208 Q1880.02 740.177 1884.22 733.875 Q1888.45 727.541 1896.44 727.541 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2326.12 770.51 L2348.56 770.51 L2348.56 775.921 L2318.39 775.921 L2318.39 770.51 Q2322.05 766.722 2328.35 760.356 Q2334.69 753.959 2336.31 752.113 Q2339.4 748.644 2340.61 746.256 Q2341.85 743.837 2341.85 741.514 Q2341.85 737.726 2339.17 735.339 Q2336.53 732.952 2332.27 732.952 Q2329.24 732.952 2325.87 734.002 Q2322.53 735.053 2318.71 737.185 L2318.71 730.692 Q2322.59 729.133 2325.97 728.337 Q2329.34 727.541 2332.14 727.541 Q2339.52 727.541 2343.92 731.233 Q2348.31 734.925 2348.31 741.1 Q2348.31 744.028 2347.2 746.67 Q2346.11 749.28 2343.22 752.845 Q2342.42 753.768 2338.16 758.192 Q2333.89 762.584 2326.12 770.51 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2375.81 732.634 Q2370.84 732.634 2368.33 737.535 Q2365.85 742.405 2365.85 752.208 Q2365.85 761.98 2368.33 766.881 Q2370.84 771.751 2375.81 771.751 Q2380.81 771.751 2383.29 766.881 Q2385.8 761.98 2385.8 752.208 Q2385.8 742.405 2383.29 737.535 Q2380.81 732.634 2375.81 732.634 M2375.81 727.541 Q2383.8 727.541 2388 733.875 Q2392.23 740.177 2392.23 752.208 Q2392.23 764.208 2388 770.542 Q2383.8 776.844 2375.81 776.844 Q2367.82 776.844 2363.59 770.542 Q2359.39 764.208 2359.39 752.208 Q2359.39 740.177 2363.59 733.875 Q2367.82 727.541 2375.81 727.541 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2417.28 732.634 Q2412.32 732.634 2409.8 737.535 Q2407.32 742.405 2407.32 752.208 Q2407.32 761.98 2409.8 766.881 Q2412.32 771.751 2417.28 771.751 Q2422.28 771.751 2424.76 766.881 Q2427.28 761.98 2427.28 752.208 Q2427.28 742.405 2424.76 737.535 Q2422.28 732.634 2417.28 732.634 M2417.28 727.541 Q2425.27 727.541 2429.47 733.875 Q2433.71 740.177 2433.71 752.208 Q2433.71 764.208 2429.47 770.542 Q2425.27 776.844 2417.28 776.844 Q2409.29 776.844 2405.06 770.542 Q2400.86 764.208 2400.86 752.208 Q2400.86 740.177 2405.06 733.875 Q2409.29 727.541 2417.28 727.541 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1199.88 816.113 L1235.39 816.113 L1235.39 822.507 L1207.48 822.507 L1207.48 839.133 L1234.22 839.133 L1234.22 845.528 L1207.48 845.528 L1207.48 865.878 L1236.07 865.878 L1236.07 872.273 L1199.88 872.273 L1199.88 816.113 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1254.95 865.953 L1254.95 888.297 L1247.99 888.297 L1247.99 830.143 L1254.95 830.143 L1254.95 836.538 Q1257.13 832.776 1260.44 830.971 Q1263.79 829.128 1268.42 829.128 Q1276.09 829.128 1280.87 835.221 Q1285.68 841.315 1285.68 851.245 Q1285.68 861.176 1280.87 867.27 Q1276.09 873.363 1268.42 873.363 Q1263.79 873.363 1260.44 871.558 Q1257.13 869.715 1254.95 865.953 M1278.5 851.245 Q1278.5 843.61 1275.34 839.284 Q1272.21 834.92 1266.72 834.92 Q1261.23 834.92 1258.07 839.284 Q1254.95 843.61 1254.95 851.245 Q1254.95 858.881 1258.07 863.245 Q1261.23 867.571 1266.72 867.571 Q1272.21 867.571 1275.34 863.245 Q1278.5 858.881 1278.5 851.245 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1313.48 834.996 Q1307.91 834.996 1304.68 839.359 Q1301.44 843.685 1301.44 851.245 Q1301.44 858.806 1304.64 863.17 Q1307.87 867.495 1313.48 867.495 Q1319.01 867.495 1322.24 863.132 Q1325.48 858.769 1325.48 851.245 Q1325.48 843.76 1322.24 839.397 Q1319.01 834.996 1313.48 834.996 M1313.48 829.128 Q1322.51 829.128 1327.66 834.996 Q1332.81 840.864 1332.81 851.245 Q1332.81 861.59 1327.66 867.495 Q1322.51 873.363 1313.48 873.363 Q1304.41 873.363 1299.26 867.495 Q1294.14 861.59 1294.14 851.245 Q1294.14 840.864 1299.26 834.996 Q1304.41 829.128 1313.48 829.128 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1374.6 831.761 L1374.6 838.231 Q1371.67 836.613 1368.7 835.823 Q1365.76 834.996 1362.75 834.996 Q1356.02 834.996 1352.3 839.284 Q1348.57 843.534 1348.57 851.245 Q1348.57 858.957 1352.3 863.245 Q1356.02 867.495 1362.75 867.495 Q1365.76 867.495 1368.7 866.705 Q1371.67 865.878 1374.6 864.26 L1374.6 870.655 Q1371.71 872.009 1368.59 872.686 Q1365.5 873.363 1362 873.363 Q1352.49 873.363 1346.88 867.383 Q1341.28 861.402 1341.28 851.245 Q1341.28 840.939 1346.92 835.033 Q1352.6 829.128 1362.45 829.128 Q1365.65 829.128 1368.7 829.805 Q1371.75 830.444 1374.6 831.761 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1421.66 846.844 L1421.66 872.273 L1414.74 872.273 L1414.74 847.07 Q1414.74 841.089 1412.41 838.118 Q1410.08 835.146 1405.41 835.146 Q1399.81 835.146 1396.57 838.72 Q1393.34 842.293 1393.34 848.462 L1393.34 872.273 L1386.38 872.273 L1386.38 813.743 L1393.34 813.743 L1393.34 836.688 Q1395.82 832.889 1399.17 831.008 Q1402.55 829.128 1406.95 829.128 Q1414.21 829.128 1417.94 833.641 Q1421.66 838.118 1421.66 846.844 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  236.659,612.62 2384.88,612.62 \n  \"/>\n<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  236.659,465.993 2384.88,465.993 \n  \"/>\n<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  236.659,319.365 2384.88,319.365 \n  \"/>\n<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  236.659,172.737 2384.88,172.737 \n  \"/>\n<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n  236.659,26.1089 2384.88,26.1089 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  236.659,697.001 236.659,15.748 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  2384.88,697.001 2384.88,15.748 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  236.659,612.62 255.556,612.62 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  236.659,465.993 255.556,465.993 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  236.659,319.365 255.556,319.365 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  236.659,172.737 255.556,172.737 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  236.659,26.1089 255.556,26.1089 \n  \"/>\n<path clip-path=\"url(#clip210)\" d=\"M121.219 593.094 Q116.254 593.094 113.74 597.995 Q111.257 602.865 111.257 612.668 Q111.257 622.44 113.74 627.341 Q116.254 632.211 121.219 632.211 Q126.216 632.211 128.699 627.341 Q131.213 622.44 131.213 612.668 Q131.213 602.865 128.699 597.995 Q126.216 593.094 121.219 593.094 M121.219 588.001 Q129.208 588.001 133.41 594.335 Q137.643 600.637 137.643 612.668 Q137.643 624.668 133.41 631.001 Q129.208 637.303 121.219 637.303 Q113.23 637.303 108.997 631.001 Q104.796 624.668 104.796 612.668 Q104.796 600.637 108.997 594.335 Q113.23 588.001 121.219 588.001 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M148.942 628.296 L155.658 628.296 L155.658 636.38 L148.942 636.38 L148.942 628.296 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M184.208 610.058 Q179.879 610.058 177.333 613.018 Q174.819 615.978 174.819 621.135 Q174.819 626.259 177.333 629.251 Q179.879 632.211 184.208 632.211 Q188.537 632.211 191.051 629.251 Q193.597 626.259 193.597 621.135 Q193.597 615.978 191.051 613.018 Q188.537 610.058 184.208 610.058 M196.971 589.911 L196.971 595.767 Q194.552 594.621 192.07 594.017 Q189.619 593.412 187.2 593.412 Q180.834 593.412 177.46 597.709 Q174.118 602.006 173.641 610.695 Q175.519 607.926 178.352 606.462 Q181.184 604.966 184.59 604.966 Q191.751 604.966 195.889 609.326 Q200.059 613.655 200.059 621.135 Q200.059 628.455 195.73 632.879 Q191.401 637.303 184.208 637.303 Q175.964 637.303 171.604 631.001 Q167.243 624.668 167.243 612.668 Q167.243 601.401 172.591 594.717 Q177.938 588.001 186.945 588.001 Q189.364 588.001 191.815 588.479 Q194.298 588.956 196.971 589.911 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M122.683 446.466 Q117.718 446.466 115.204 451.367 Q112.721 456.237 112.721 466.04 Q112.721 475.812 115.204 480.713 Q117.718 485.583 122.683 485.583 Q127.681 485.583 130.163 480.713 Q132.678 475.812 132.678 466.04 Q132.678 456.237 130.163 451.367 Q127.681 446.466 122.683 446.466 M122.683 441.373 Q130.672 441.373 134.874 447.707 Q139.107 454.009 139.107 466.04 Q139.107 478.04 134.874 484.374 Q130.672 490.676 122.683 490.676 Q114.694 490.676 110.461 484.374 Q106.26 478.04 106.26 466.04 Q106.26 454.009 110.461 447.707 Q114.694 441.373 122.683 441.373 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M150.406 481.668 L157.122 481.668 L157.122 489.753 L150.406 489.753 L150.406 481.668 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M169.503 442.233 L200.059 442.233 L200.059 444.97 L182.808 489.753 L176.092 489.753 L192.324 447.643 L169.503 447.643 L169.503 442.233 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M121.569 299.838 Q116.604 299.838 114.09 304.739 Q111.607 309.609 111.607 319.412 Q111.607 329.184 114.09 334.085 Q116.604 338.955 121.569 338.955 Q126.567 338.955 129.049 334.085 Q131.564 329.184 131.564 319.412 Q131.564 309.609 129.049 304.739 Q126.567 299.838 121.569 299.838 M121.569 294.745 Q129.558 294.745 133.76 301.079 Q137.993 307.381 137.993 319.412 Q137.993 331.412 133.76 337.746 Q129.558 344.048 121.569 344.048 Q113.58 344.048 109.347 337.746 Q105.146 331.412 105.146 319.412 Q105.146 307.381 109.347 301.079 Q113.58 294.745 121.569 294.745 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M149.292 335.04 L156.008 335.04 L156.008 343.125 L149.292 343.125 L149.292 335.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M183.762 320.558 Q179.179 320.558 176.537 323.009 Q173.927 325.46 173.927 329.757 Q173.927 334.054 176.537 336.504 Q179.179 338.955 183.762 338.955 Q188.346 338.955 190.987 336.504 Q193.629 334.022 193.629 329.757 Q193.629 325.46 190.987 323.009 Q188.378 320.558 183.762 320.558 M177.333 317.821 Q173.195 316.802 170.872 313.97 Q168.58 311.137 168.58 307.063 Q168.58 301.366 172.622 298.055 Q176.696 294.745 183.762 294.745 Q190.86 294.745 194.902 298.055 Q198.945 301.366 198.945 307.063 Q198.945 311.137 196.621 313.97 Q194.329 316.802 190.224 317.821 Q194.871 318.903 197.449 322.054 Q200.059 325.205 200.059 329.757 Q200.059 336.663 195.825 340.356 Q191.624 344.048 183.762 344.048 Q175.901 344.048 171.668 340.356 Q167.466 336.663 167.466 329.757 Q167.466 325.205 170.076 322.054 Q172.686 318.903 177.333 317.821 M174.978 307.668 Q174.978 311.36 177.269 313.429 Q179.593 315.498 183.762 315.498 Q187.9 315.498 190.224 313.429 Q192.579 311.36 192.579 307.668 Q192.579 303.976 190.224 301.907 Q187.9 299.838 183.762 299.838 Q179.593 299.838 177.269 301.907 Q174.978 303.976 174.978 307.668 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M121.697 153.21 Q116.732 153.21 114.217 158.112 Q111.734 162.981 111.734 172.785 Q111.734 182.556 114.217 187.457 Q116.732 192.327 121.697 192.327 Q126.694 192.327 129.176 187.457 Q131.691 182.556 131.691 172.785 Q131.691 162.981 129.176 158.112 Q126.694 153.21 121.697 153.21 M121.697 148.117 Q129.686 148.117 133.887 154.451 Q138.12 160.753 138.12 172.785 Q138.12 184.784 133.887 191.118 Q129.686 197.42 121.697 197.42 Q113.708 197.42 109.475 191.118 Q105.273 184.784 105.273 172.785 Q105.273 160.753 109.475 154.451 Q113.708 148.117 121.697 148.117 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M149.419 188.412 L156.135 188.412 L156.135 196.497 L149.419 196.497 L149.419 188.412 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M170.331 195.51 L170.331 189.654 Q172.75 190.799 175.232 191.404 Q177.715 192.009 180.102 192.009 Q186.468 192.009 189.81 187.744 Q193.184 183.447 193.661 174.726 Q191.815 177.463 188.982 178.927 Q186.15 180.392 182.712 180.392 Q175.582 180.392 171.413 176.095 Q167.275 171.766 167.275 164.286 Q167.275 156.966 171.604 152.542 Q175.933 148.117 183.126 148.117 Q191.369 148.117 195.698 154.451 Q200.059 160.753 200.059 172.785 Q200.059 184.02 194.711 190.736 Q189.396 197.42 180.389 197.42 Q177.97 197.42 175.487 196.942 Q173.004 196.465 170.331 195.51 M183.126 175.363 Q187.455 175.363 189.969 172.403 Q192.515 169.443 192.515 164.286 Q192.515 159.162 189.969 156.202 Q187.455 153.21 183.126 153.21 Q178.797 153.21 176.251 156.202 Q173.736 159.162 173.736 164.286 Q173.736 169.443 176.251 172.403 Q178.797 175.363 183.126 175.363 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M108.806 44.458 L119.31 44.458 L119.31 8.20532 L107.883 10.497 L107.883 4.64053 L119.246 2.34887 L125.675 2.34887 L125.675 44.458 L136.179 44.458 L136.179 49.8689 L108.806 49.8689 L108.806 44.458 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M149.165 41.7844 L155.881 41.7844 L155.881 49.8689 L149.165 49.8689 L149.165 41.7844 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M183.635 6.58207 Q178.67 6.58207 176.155 11.4837 Q173.673 16.3534 173.673 26.1566 Q173.673 35.928 176.155 40.8296 Q178.67 45.6993 183.635 45.6993 Q188.632 45.6993 191.115 40.8296 Q193.629 35.928 193.629 26.1566 Q193.629 16.3534 191.115 11.4837 Q188.632 6.58207 183.635 6.58207 M183.635 1.4895 Q191.624 1.4895 195.825 7.82338 Q200.059 14.1254 200.059 26.1566 Q200.059 38.156 195.825 44.4899 Q191.624 50.7919 183.635 50.7919 Q175.646 50.7919 171.413 44.4899 Q167.212 38.156 167.212 26.1566 Q167.212 14.1254 171.413 7.82338 Q175.646 1.4895 183.635 1.4895 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M-4.81219 435.198 L-4.81219 427.599 L44.9532 427.599 L44.9532 400.253 L51.3478 400.253 L51.3478 435.198 L-4.81219 435.198 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M14.0708 377.608 Q14.0708 383.175 18.4342 386.41 Q22.76 389.645 30.3207 389.645 Q37.8814 389.645 42.2449 386.448 Q46.5706 383.213 46.5706 377.608 Q46.5706 372.079 42.2072 368.844 Q37.8438 365.609 30.3207 365.609 Q22.8352 365.609 18.4718 368.844 Q14.0708 372.079 14.0708 377.608 M8.20279 377.608 Q8.20279 368.581 14.0708 363.427 Q19.9388 358.274 30.3207 358.274 Q40.665 358.274 46.5706 363.427 Q52.4387 368.581 52.4387 377.608 Q52.4387 386.674 46.5706 391.827 Q40.665 396.943 30.3207 396.943 Q19.9388 396.943 14.0708 391.827 Q8.20279 386.674 8.20279 377.608 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M10.4597 319.944 L17.0048 319.944 Q15.5002 322.878 14.7479 326.037 Q13.9956 329.197 13.9956 332.582 Q13.9956 337.736 15.5754 340.331 Q17.1553 342.889 20.315 342.889 Q22.7224 342.889 24.1142 341.046 Q25.4683 339.203 26.7096 333.636 L27.2363 331.266 Q28.8161 323.893 31.7125 320.809 Q34.5713 317.687 39.7246 317.687 Q45.5926 317.687 49.0156 322.351 Q52.4387 326.978 52.4387 335.103 Q52.4387 338.488 51.7616 342.174 Q51.1221 345.823 49.8056 349.886 L42.6586 349.886 Q44.6522 346.049 45.6679 342.325 Q46.6459 338.601 46.6459 334.952 Q46.6459 330.062 44.9908 327.429 Q43.2981 324.796 40.2512 324.796 Q37.4301 324.796 35.9254 326.714 Q34.4208 328.595 33.029 335.027 L32.4648 337.435 Q31.1107 343.867 28.3271 346.726 Q25.5059 349.585 20.6159 349.585 Q14.6727 349.585 11.4377 345.372 Q8.20279 341.159 8.20279 333.41 Q8.20279 329.573 8.76702 326.188 Q9.33126 322.802 10.4597 319.944 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M10.4597 279.808 L17.0048 279.808 Q15.5002 282.742 14.7479 285.902 Q13.9956 289.061 13.9956 292.447 Q13.9956 297.6 15.5754 300.195 Q17.1553 302.753 20.315 302.753 Q22.7224 302.753 24.1142 300.91 Q25.4683 299.067 26.7096 293.5 L27.2363 291.13 Q28.8161 283.758 31.7125 280.673 Q34.5713 277.551 39.7246 277.551 Q45.5926 277.551 49.0156 282.215 Q52.4387 286.842 52.4387 294.967 Q52.4387 298.352 51.7616 302.039 Q51.1221 305.687 49.8056 309.75 L42.6586 309.75 Q44.6522 305.913 45.6679 302.189 Q46.6459 298.465 46.6459 294.816 Q46.6459 289.926 44.9908 287.293 Q43.2981 284.66 40.2512 284.66 Q37.4301 284.66 35.9254 286.579 Q34.4208 288.459 33.029 294.892 L32.4648 297.299 Q31.1107 303.731 28.3271 306.59 Q25.5059 309.449 20.6159 309.449 Q14.6727 309.449 11.4377 305.236 Q8.20279 301.023 8.20279 293.274 Q8.20279 289.437 8.76702 286.052 Q9.33126 282.667 10.4597 279.808 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip212)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  297.457,35.0288 307.85,204.552 318.243,272.577 328.636,332.47 339.029,383.589 349.422,431.308 359.815,467.316 370.208,503.125 380.601,523.246 390.994,535.246 \n  401.387,551.762 411.78,560.485 422.173,568.454 432.566,573.557 442.959,584.759 453.352,580.435 463.745,597.254 474.138,596.497 484.531,603.987 494.923,607.714 \n  505.316,614.768 515.709,619.481 526.102,620.254 536.495,626.253 546.888,626.328 557.281,631.77 567.674,627.49 578.067,631.806 588.46,637.992 598.853,638.293 \n  609.246,630.541 619.639,635.476 630.032,639.624 640.425,641.909 650.818,642.476 661.211,645.276 671.604,641.241 681.997,642.678 692.39,645.463 702.783,649.216 \n  713.175,644.229 723.568,650.172 733.961,649.721 744.354,647.737 754.747,650.063 765.14,644.245 775.533,652.89 785.926,654.372 796.319,649.294 806.712,648.212 \n  817.105,654.631 827.498,656.043 837.891,651.622 848.284,649.426 858.677,642.764 869.07,654.696 879.463,655.804 889.856,648.902 900.249,655.379 910.642,657.483 \n  921.035,657.632 931.427,653.189 941.82,660.346 952.213,657.67 962.606,654.339 972.999,661.133 983.392,651.552 993.785,661.21 1004.18,661.82 1014.57,647.126 \n  1024.96,621.648 1035.36,662.716 1045.75,653.684 1056.14,660.865 1066.54,658.588 1076.93,659.875 1087.32,652.555 1097.71,662.622 1108.11,663.682 1118.5,662.78 \n  1128.89,664.161 1139.29,662.463 1149.68,664.978 1160.07,663.969 1170.47,649.517 1180.86,662.129 1191.25,664.857 1201.64,666.425 1212.04,662.853 1222.43,666.407 \n  1232.82,665.49 1243.22,666.44 1253.61,665.902 1264,667.382 1274.39,661.873 1284.79,659.1 1295.18,666.133 1305.57,668.145 1315.97,666.779 1326.36,661.694 \n  1336.75,666.461 1347.15,666.448 1357.54,666.076 1367.93,667.952 1378.32,667.797 1388.72,665.461 1399.11,667.693 1409.5,669.748 1419.9,662.374 1430.29,664.126 \n  1440.68,668.165 1451.08,633.257 1461.47,667.691 1471.86,669.632 1482.25,662.665 1492.65,665.583 1503.04,666.241 1513.43,669.053 1523.83,666.087 1534.22,669.967 \n  1544.61,661.18 1555,663.753 1565.4,670.118 1575.79,671.605 1586.18,669.24 1596.58,669.896 1606.97,663.674 1617.36,670.226 1627.76,670.812 1638.15,666.26 \n  1648.54,668.631 1658.93,670.19 1669.33,670.981 1679.72,664.341 1690.11,670.701 1700.51,672.425 1710.9,672.37 1721.29,670.881 1731.68,671.485 1742.08,672.233 \n  1752.47,669.55 1762.86,664.087 1773.26,671.709 1783.65,663.267 1794.04,671.593 1804.44,671.752 1814.83,669.531 1825.22,673.937 1835.61,669.024 1846.01,670.912 \n  1856.4,670.929 1866.79,666.467 1877.19,668.161 1887.58,671.472 1897.97,673 1908.37,669.654 1918.76,674.108 1929.15,673.528 1939.54,672.953 1949.94,672.963 \n  1960.33,668.303 1970.72,672.623 1981.12,674.126 1991.51,672.951 2001.9,662.675 2012.29,643.973 2022.69,666.121 2033.08,670.68 2043.47,673.967 2053.87,673.041 \n  2064.26,671.125 2074.65,674.176 2085.05,674.451 2095.44,646.63 2105.83,663.199 2116.22,667.778 2126.62,673.545 2137.01,666.808 2147.4,672.727 2157.8,652.771 \n  2168.19,673.161 2178.58,674.676 2188.97,670.975 2199.37,673.607 2209.76,675.139 2220.15,676.348 2230.55,675.331 2240.94,676.891 2251.33,674.421 2261.73,675.787 \n  2272.12,674.686 2282.51,674.398 2292.9,670.315 2303.3,677.409 2313.69,677.72 2324.08,676.701 \n  \"/>\n<polyline clip-path=\"url(#clip212)\" style=\"stroke:#e26f46; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  297.457,59.1039 307.85,268.618 318.243,368.3 328.636,413.711 339.029,460.794 349.422,509.268 359.815,542.897 370.208,564.59 380.601,587.181 390.994,598.023 \n  401.387,610.284 411.78,613.687 422.173,617.786 432.566,621.737 442.959,627.784 453.352,615.349 463.745,627.027 474.138,615.462 484.531,620.961 494.923,620.051 \n  505.316,632.46 515.709,634.911 526.102,628.558 536.495,637.901 546.888,627.538 557.281,636.03 567.674,622.64 578.067,628.29 588.46,639.639 598.853,634.443 \n  609.246,636.986 619.639,641.981 630.032,645.851 640.425,633.301 650.818,635.108 661.211,646.781 671.604,634.358 681.997,628.553 692.39,644.896 702.783,640.958 \n  713.175,632.492 723.568,636.808 733.961,638.309 744.354,631.113 754.747,635.018 765.14,632.355 775.533,639.198 785.926,644.281 796.319,639.487 806.712,630.741 \n  817.105,637.972 827.498,637.522 837.891,635.64 848.284,641.22 858.677,622.288 869.07,641.683 879.463,646.412 889.856,623.735 900.249,640.053 910.642,642.358 \n  921.035,637.477 931.427,634.939 941.82,640.756 952.213,642.404 962.606,642.831 972.999,646.211 983.392,634.001 993.785,643.024 1004.18,640.309 1014.57,622.738 \n  1024.96,616.918 1035.36,641.217 1045.75,629.549 1056.14,636.796 1066.54,642.663 1076.93,634.561 1087.32,636.925 1097.71,644.644 1108.11,638.936 1118.5,639.646 \n  1128.89,637.244 1139.29,640.283 1149.68,636.132 1160.07,639.244 1170.47,631.54 1180.86,645.932 1191.25,636.082 1201.64,643.185 1212.04,642.811 1222.43,638.272 \n  1232.82,637.372 1243.22,640.462 1253.61,644.023 1264,636.248 1274.39,641.697 1284.79,633.727 1295.18,641.43 1305.57,641.729 1315.97,634.332 1326.36,632.913 \n  1336.75,643.108 1347.15,635.054 1357.54,635.088 1367.93,636.543 1378.32,638.11 1388.72,642.491 1399.11,630.919 1409.5,638.883 1419.9,635.629 1430.29,627.817 \n  1440.68,634.393 1451.08,615.586 1461.47,636.728 1471.86,640.645 1482.25,625.072 1492.65,634.022 1503.04,638.565 1513.43,640.409 1523.83,640.29 1534.22,635.653 \n  1544.61,634.233 1555,634.625 1565.4,637.764 1575.79,637.02 1586.18,638.448 1596.58,635.58 1606.97,631.171 1617.36,635.441 1627.76,631.604 1638.15,636.139 \n  1648.54,631.013 1658.93,634.735 1669.33,637.228 1679.72,631.516 1690.11,638.243 1700.51,637.921 1710.9,634.995 1721.29,640.235 1731.68,637.448 1742.08,635.568 \n  1752.47,638.093 1762.86,621.963 1773.26,635.422 1783.65,629.265 1794.04,634.048 1804.44,634.309 1814.83,631.866 1825.22,638.113 1835.61,631.711 1846.01,634.047 \n  1856.4,630.908 1866.79,634.208 1877.19,635.484 1887.58,634.464 1897.97,638.381 1908.37,635.535 1918.76,636.517 1929.15,633.287 1939.54,633.21 1949.94,633.11 \n  1960.33,630.481 1970.72,634.53 1981.12,632.719 1991.51,640.215 2001.9,635.484 2012.29,605.136 2022.69,629.447 2033.08,637.604 2043.47,635.3 2053.87,633.7 \n  2064.26,639.522 2074.65,639.983 2085.05,638.342 2095.44,618.854 2105.83,631.081 2116.22,624.921 2126.62,633.871 2137.01,623.385 2147.4,638.87 2157.8,613.087 \n  2168.19,634.65 2178.58,637.101 2188.97,639.285 2199.37,635.307 2209.76,632.437 2220.15,637.717 2230.55,637.166 2240.94,637.609 2251.33,636.366 2261.73,635.915 \n  2272.12,633.967 2282.51,635.506 2292.9,625.314 2303.3,638.565 2313.69,636.25 2324.08,639.475 \n  \"/>\n<path clip-path=\"url(#clip210)\" d=\"\nM1761.14 252.296 L2313.27 252.296 L2313.27 38.4564 L1761.14 38.4564  Z\n  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n  1761.14,252.296 2313.27,252.296 2313.27,38.4564 1761.14,38.4564 1761.14,252.296 \n  \"/>\n<polyline clip-path=\"url(#clip210)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:5.5; stroke-opacity:1; fill:none\" points=\"\n  1785,109.736 1928.22,109.736 \n  \"/>\n<path clip-path=\"url(#clip210)\" d=\"M1962.27 87.727 L1962.27 97.8485 L1974.34 97.8485 L1974.34 102.4 L1962.27 102.4 L1962.27 121.752 Q1962.27 126.112 1963.45 127.354 Q1964.66 128.595 1968.32 128.595 L1974.34 128.595 L1974.34 133.496 L1968.32 133.496 Q1961.54 133.496 1958.96 130.982 Q1956.39 128.436 1956.39 121.752 L1956.39 102.4 L1952.09 102.4 L1952.09 97.8485 L1956.39 97.8485 L1956.39 87.727 L1962.27 87.727 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2002.7 103.323 Q2001.71 102.75 2000.53 102.495 Q1999.39 102.209 1997.99 102.209 Q1993.02 102.209 1990.35 105.456 Q1987.7 108.67 1987.7 114.718 L1987.7 133.496 L1981.82 133.496 L1981.82 97.8485 L1987.7 97.8485 L1987.7 103.387 Q1989.55 100.14 1992.51 98.5805 Q1995.47 96.9891 1999.7 96.9891 Q2000.31 96.9891 2001.04 97.0846 Q2001.77 97.1483 2002.66 97.3074 L2002.7 103.323 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2025.04 115.577 Q2017.94 115.577 2015.2 117.2 Q2012.47 118.823 2012.47 122.738 Q2012.47 125.858 2014.5 127.704 Q2016.57 129.518 2020.11 129.518 Q2024.98 129.518 2027.9 126.08 Q2030.86 122.611 2030.86 116.882 L2030.86 115.577 L2025.04 115.577 M2036.72 113.158 L2036.72 133.496 L2030.86 133.496 L2030.86 128.086 Q2028.86 131.332 2025.87 132.892 Q2022.88 134.419 2018.55 134.419 Q2013.07 134.419 2009.83 131.364 Q2006.61 128.277 2006.61 123.12 Q2006.61 117.105 2010.62 114.049 Q2014.66 110.994 2022.65 110.994 L2030.86 110.994 L2030.86 110.421 Q2030.86 106.379 2028.19 104.182 Q2025.55 101.954 2020.74 101.954 Q2017.69 101.954 2014.79 102.686 Q2011.89 103.418 2009.22 104.883 L2009.22 99.4717 Q2012.44 98.2304 2015.46 97.6257 Q2018.48 96.9891 2021.35 96.9891 Q2029.08 96.9891 2032.9 101 Q2036.72 105.01 2036.72 113.158 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2048.78 97.8485 L2054.64 97.8485 L2054.64 133.496 L2048.78 133.496 L2048.78 97.8485 M2048.78 83.9713 L2054.64 83.9713 L2054.64 91.3873 L2048.78 91.3873 L2048.78 83.9713 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2096.53 111.98 L2096.53 133.496 L2090.67 133.496 L2090.67 112.171 Q2090.67 107.111 2088.7 104.596 Q2086.72 102.082 2082.78 102.082 Q2078.03 102.082 2075.3 105.105 Q2072.56 108.129 2072.56 113.349 L2072.56 133.496 L2066.67 133.496 L2066.67 97.8485 L2072.56 97.8485 L2072.56 103.387 Q2074.66 100.172 2077.49 98.5805 Q2080.36 96.9891 2084.08 96.9891 Q2090.22 96.9891 2093.38 100.809 Q2096.53 104.596 2096.53 111.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip210)\" style=\"stroke:#e26f46; stroke-linecap:butt; stroke-linejoin:round; stroke-width:5.5; stroke-opacity:1; fill:none\" points=\"\n  1785,181.016 1928.22,181.016 \n  \"/>\n<path clip-path=\"url(#clip210)\" d=\"M1952.09 169.128 L1958.3 169.128 L1969.44 199.047 L1980.58 169.128 L1986.78 169.128 L1973.41 204.776 L1965.46 204.776 L1952.09 169.128 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2011.07 186.857 Q2003.97 186.857 2001.23 188.48 Q1998.49 190.103 1998.49 194.018 Q1998.49 197.138 2000.53 198.984 Q2002.6 200.798 2006.13 200.798 Q2011 200.798 2013.93 197.36 Q2016.89 193.891 2016.89 188.162 L2016.89 186.857 L2011.07 186.857 M2022.75 184.438 L2022.75 204.776 L2016.89 204.776 L2016.89 199.366 Q2014.89 202.612 2011.89 204.172 Q2008.9 205.699 2004.57 205.699 Q1999.1 205.699 1995.85 202.644 Q1992.64 199.557 1992.64 194.4 Q1992.64 188.385 1996.65 185.329 Q2000.69 182.274 2008.68 182.274 L2016.89 182.274 L2016.89 181.701 Q2016.89 177.659 2014.22 175.462 Q2011.58 173.234 2006.77 173.234 Q2003.71 173.234 2000.82 173.966 Q1997.92 174.698 1995.25 176.163 L1995.25 170.752 Q1998.46 169.51 2001.49 168.906 Q2004.51 168.269 2007.37 168.269 Q2015.11 168.269 2018.93 172.28 Q2022.75 176.29 2022.75 184.438 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2034.81 155.251 L2040.67 155.251 L2040.67 204.776 L2034.81 204.776 L2034.81 155.251 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2052.92 169.128 L2058.78 169.128 L2058.78 204.776 L2052.92 204.776 L2052.92 169.128 M2052.92 155.251 L2058.78 155.251 L2058.78 162.667 L2052.92 162.667 L2052.92 155.251 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2094.49 174.539 L2094.49 155.251 L2100.35 155.251 L2100.35 204.776 L2094.49 204.776 L2094.49 199.429 Q2092.64 202.612 2089.81 204.172 Q2087.01 205.699 2083.06 205.699 Q2076.6 205.699 2072.53 200.543 Q2068.49 195.387 2068.49 186.984 Q2068.49 178.582 2072.53 173.425 Q2076.6 168.269 2083.06 168.269 Q2087.01 168.269 2089.81 169.829 Q2092.64 171.356 2094.49 174.539 M2074.53 186.984 Q2074.53 193.445 2077.17 197.138 Q2079.85 200.798 2084.5 200.798 Q2089.14 200.798 2091.82 197.138 Q2094.49 193.445 2094.49 186.984 Q2094.49 180.523 2091.82 176.863 Q2089.14 173.171 2084.5 173.171 Q2079.85 173.171 2077.17 176.863 Q2074.53 180.523 2074.53 186.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2128.61 186.857 Q2121.51 186.857 2118.77 188.48 Q2116.04 190.103 2116.04 194.018 Q2116.04 197.138 2118.07 198.984 Q2120.14 200.798 2123.68 200.798 Q2128.55 200.798 2131.47 197.36 Q2134.43 193.891 2134.43 188.162 L2134.43 186.857 L2128.61 186.857 M2140.29 184.438 L2140.29 204.776 L2134.43 204.776 L2134.43 199.366 Q2132.43 202.612 2129.44 204.172 Q2126.45 205.699 2122.12 205.699 Q2116.64 205.699 2113.4 202.644 Q2110.18 199.557 2110.18 194.4 Q2110.18 188.385 2114.19 185.329 Q2118.23 182.274 2126.22 182.274 L2134.43 182.274 L2134.43 181.701 Q2134.43 177.659 2131.76 175.462 Q2129.12 173.234 2124.31 173.234 Q2121.26 173.234 2118.36 173.966 Q2115.46 174.698 2112.79 176.163 L2112.79 170.752 Q2116.01 169.51 2119.03 168.906 Q2122.05 168.269 2124.92 168.269 Q2132.65 168.269 2136.47 172.28 Q2140.29 176.29 2140.29 184.438 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2158.15 159.007 L2158.15 169.128 L2170.21 169.128 L2170.21 173.68 L2158.15 173.68 L2158.15 193.032 Q2158.15 197.392 2159.32 198.634 Q2160.53 199.875 2164.19 199.875 L2170.21 199.875 L2170.21 204.776 L2164.19 204.776 Q2157.41 204.776 2154.84 202.262 Q2152.26 199.716 2152.26 193.032 L2152.26 173.68 L2147.96 173.68 L2147.96 169.128 L2152.26 169.128 L2152.26 159.007 L2158.15 159.007 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2177.91 169.128 L2183.77 169.128 L2183.77 204.776 L2177.91 204.776 L2177.91 169.128 M2177.91 155.251 L2183.77 155.251 L2183.77 162.667 L2177.91 162.667 L2177.91 155.251 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2209.84 173.234 Q2205.13 173.234 2202.39 176.926 Q2199.65 180.587 2199.65 186.984 Q2199.65 193.382 2202.36 197.074 Q2205.09 200.734 2209.84 200.734 Q2214.52 200.734 2217.25 197.042 Q2219.99 193.35 2219.99 186.984 Q2219.99 180.65 2217.25 176.958 Q2214.52 173.234 2209.84 173.234 M2209.84 168.269 Q2217.48 168.269 2221.84 173.234 Q2226.2 178.2 2226.2 186.984 Q2226.2 195.737 2221.84 200.734 Q2217.48 205.699 2209.84 205.699 Q2202.17 205.699 2197.81 200.734 Q2193.48 195.737 2193.48 186.984 Q2193.48 178.2 2197.81 173.234 Q2202.17 168.269 2209.84 168.269 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2265.54 183.26 L2265.54 204.776 L2259.68 204.776 L2259.68 183.451 Q2259.68 178.391 2257.71 175.876 Q2255.73 173.362 2251.79 173.362 Q2247.04 173.362 2244.31 176.385 Q2241.57 179.409 2241.57 184.629 L2241.57 204.776 L2235.68 204.776 L2235.68 169.128 L2241.57 169.128 L2241.57 174.667 Q2243.67 171.452 2246.5 169.861 Q2249.37 168.269 2253.09 168.269 Q2259.23 168.269 2262.39 172.089 Q2265.54 175.876 2265.54 183.26 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wi = 3  # which shiftable load \n",
    "loss_hist = loss_histories[wi]\n",
    "id = shiftable_loads[wi]\n",
    "ne = size(loss_hist)[1]\n",
    "@show id ne\n",
    "plot(; size = (610, 220), xlabel = \"Epoch\", ylabel = \"Loss\")\n",
    "plot!(0:ne-1, loss_hist; label=[\"train\" \"validation\"], bottom_margin=3.5mm, top_margin=-1mm, left_margin=1.5mm, right_margin=1.5mm)\n",
    "savefig(joinpath(img_dir, \"train_$(id).pdf\"))\n",
    "current()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id = \"WM\"\n",
      "- Training performance\n",
      "cm = MLJBase.ConfusionMatrixObject{2}([2683 131; 241 600], [\"0.0\", \"1.0\"])\n",
      "acc = 0.8982216142270862\n",
      "f1 = 0.7633587786259542\n",
      "- Test performance\n",
      "cm = MLJBase.ConfusionMatrixObject{2}([1201 111; 259 254], [\"0.0\", \"1.0\"])\n",
      "acc = 0.7972602739726027\n",
      "f1 = 0.5785876993166287\n",
      "id = \"DW\"\n",
      "- Training performance\n",
      "cm = MLJBase.ConfusionMatrixObject{2}([1311 67; 151 664], [\"0.0\", \"1.0\"])\n",
      "acc = 0.9005927952576379\n",
      "f1 = 0.8589909443725744\n",
      "- Test performance\n",
      "cm = MLJBase.ConfusionMatrixObject{2}([544 48; 186 317], [\"0.0\", \"1.0\"])\n",
      "acc = 0.7863013698630137\n",
      "f1 = 0.7304147465437788\n",
      "id = \"EV\"\n",
      "- Training performance\n",
      "cm = MLJBase.ConfusionMatrixObject{2}([1767 124; 1157 2800], [\"0.0\", \"1.0\"])\n",
      "acc = 0.7809507523939808\n",
      "f1 = 0.8138351983723296\n",
      "- Test performance\n",
      "cm = MLJBase.ConfusionMatrixObject{2}([864 81; 596 1379], [\"0.0\", \"1.0\"])\n",
      "acc = 0.7681506849315068\n",
      "f1 = 0.8029112081513828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The classes are un-ordered,\n",
      "│ using: negative='0.0' and positive='1.0'.\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase C:\\Users\\shuhu\\.julia\\packages\\MLJBase\\GxHVg\\src\\measures\\confusion_matrix.jl:112\n",
      "┌ Warning: The classes are un-ordered,\n",
      "│ using: negative='0.0' and positive='1.0'.\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase C:\\Users\\shuhu\\.julia\\packages\\MLJBase\\GxHVg\\src\\measures\\confusion_matrix.jl:112\n",
      "┌ Warning: The classes are un-ordered,\n",
      "│ using: negative='0.0' and positive='1.0'.\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase C:\\Users\\shuhu\\.julia\\packages\\MLJBase\\GxHVg\\src\\measures\\confusion_matrix.jl:112\n",
      "┌ Warning: The classes are un-ordered,\n",
      "│ using: negative='0.0' and positive='1.0'.\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase C:\\Users\\shuhu\\.julia\\packages\\MLJBase\\GxHVg\\src\\measures\\confusion_matrix.jl:112\n",
      "┌ Warning: The classes are un-ordered,\n",
      "│ using: negative='0.0' and positive='1.0'.\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase C:\\Users\\shuhu\\.julia\\packages\\MLJBase\\GxHVg\\src\\measures\\confusion_matrix.jl:112\n",
      "┌ Warning: The classes are un-ordered,\n",
      "│ using: negative='0.0' and positive='1.0'.\n",
      "│ To suppress this warning, consider coercing to OrderedFactor.\n",
      "└ @ MLJBase C:\\Users\\shuhu\\.julia\\packages\\MLJBase\\GxHVg\\src\\measures\\confusion_matrix.jl:112\n"
     ]
    }
   ],
   "source": [
    "for (id, agent) in zip(shiftable_loads, agents)\n",
    "    @show id\n",
    "    X, y = d[id]\n",
    "    Xt, yt = dt[id]\n",
    "    println(\"- Training performance\")\n",
    "    report_classification_perf(agent, X, y)\n",
    "    println(\"- Test performance\")\n",
    "    report_classification_perf(agent, Xt, yt)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@save joinpath(IL_model_dir, \"agents.bson\") agents=Dict(id => agent for (id, agent) in zip(shiftable_loads, agents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
